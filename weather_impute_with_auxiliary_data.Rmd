---
title: "Gap filling with nearby weather stations"
author: "Quentin D. Read"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Here, I'm going to use the data from nearby weather stations that Zamir sent to try to fill in the larger gaps of the SCAN time series. The approach will be:

- Fill in any small gaps of a few hours by linear interpolation for the continuous variables (temperature, wind speed, relative humidty, radiation, and soil moisture). Do not do this for precipitation because you cannot really interpolate as it is not really a "state" of the system.
- Make a statistical model, as simple as possible, to correlate the weather variables from the SCAN time series with the other locations, for the times when they are overlapping.
- Use this statistical relationship to predict the SCAN values for the times when we do have data from one or more nearby stations but not the SCAN time series.

# Fill in the shorter gaps for variables other than precip

Load the SCAN data and do initial processing.

```{r}
library(data.table)
library(purrr)
library(glue)
library(stringr)
library(lubridate)
library(units)
library(ggplot2)
library(caret)
library(gt)
library(Rutilitybelt)

theme_set(theme_bw() + theme(
  panel.grid = element_blank(),
  strip.background = element_blank()
))

years <- 2014:2021

# Files have different number of rows to skip 
skip_n_scan <- c(2, 0, 4, 4, 4, 4, 4, 4)
skip_n_solar <- c(2, 4, 4, 4, 4, 4, 4, 4)

# Read data
scan_raw <- map2(years, skip_n_scan, ~ fread(glue('project/weather_data/2198_SCAN_WATERYEAR={.x}.csv'), skip = .y)) 
solar_raw <- map2(years, skip_n_solar, ~ fread(glue('project/weather_data/2198_SOLAR_WATERYEAR={.x}.csv'), skip = .y)) 

# Convert Date column to Date format for all, if it is not already
for (i in 1:8) {
  if (!'Date' %in% class(scan_raw[[i]][['Date']])) {
    scan_raw[[i]][, Date := as.Date(Date, format = '%m/%d/%Y')]
  } else {
    scan_raw[[i]][, Date := as.Date(Date)]
  }
  if (!'Date' %in% class(solar_raw[[i]][['Date']])) {
    solar_raw[[i]][, Date := as.Date(Date, format = '%m/%d/%Y')]
  } else {
    solar_raw[[i]][, Date := as.Date(Date)]
  }
}

scan_data <- rbindlist(scan_raw, fill = TRUE)
solar_data <- rbindlist(solar_raw, fill = TRUE)

# Get rid of bad column
scan_data[, V32 := NULL]
solar_data[, V5 := NULL]

# Get rid of bad rows that all have 23:59 as the time
scan_data <- scan_data[!Time %in% '23:59']
solar_data <- solar_data[!Time %in% '23:59']

# Some of the times are formatted differently from others. Make sure all are padded with 0 if hour has only 1 digit.
scan_data[, Time := str_pad(Time, 5, pad = '0')]
solar_data[, Time := str_pad(Time, 5, pad = '0')]
```

Join each year's data table together into one large table, create additional rows for the missing data, convert `-99.9` to `NA`, and keep only the needed variables.

```{r}
# Sort and set keys for each data table, then do a full join.
setkey(scan_data, `Site Id`, Date, Time)
setkey(solar_data, `Site Id`, Date, Time)

unique_times <- unique(rbind(scan_data[,.(`Site Id`, Date, Time)], solar_data[, .(`Site Id`, Date, Time)]))

all_raw_data <- scan_data[solar_data[unique_times]]

# Create data.frame of all the dates and times with no gaps and join the data to it, to show how many are missing.
date_range <- range(all_raw_data[['Date']])
all_date_time <- CJ(Date = seq(from = date_range[1], to = date_range[2], by = 1), Time = glue('{sprintf("%02d", 0:23)}:00'))

all_raw_data <- all_raw_data[all_date_time, on = .(Date, Time)]

# Create data frame with only the desired variables
needed_raw_data <- all_raw_data[, .(Date, Time, `TOBS.I-1 (degC)`, `WSPDX.H-1 (mph)`, `RHUM.I-1 (pct)`, `SRADV.H-1 (watt)`, `PRCP.H-1 (in)`)]

obs_vars <- c('TOBS.I-1 (degC)', 'WSPDX.H-1 (mph)', 'RHUM.I-1 (pct)', 'SRADV.H-1 (watt)', 'PRCP.H-1 (in)')

# Convert -99.9 codes to NA
needed_raw_data[, (obs_vars) := lapply(.SD, function(x) ifelse(x == -99.9, as.numeric(NA), x)), .SDcols = obs_vars]

# Add Month, Day, and Time columns
needed_raw_data[, Month := month(Date)]
needed_raw_data[, Day := day(Date)]
needed_raw_data[, Time := as.numeric(substr(Time, 1, 2))]
```

Take the rolling average over a five-hour window for the variables other than precipitation. Use these to impute the values for shorter time gaps.

```{r}
# Function with five hour moving window rolling mean 
fivehour_roll <- function(x) frollmean(x, n = 5, align = 'center', fill = NA, algo = 'exact', hasNA = TRUE, na.rm = TRUE)

mean_vars <- obs_vars[1:4]

data_fivehour_rollmean <- copy(needed_raw_data)
data_fivehour_rollmean[, (mean_vars) := lapply(.SD, fivehour_roll), .SDcols = mean_vars]

# Fill in the missing value only if needed
data_fivehour_filled <- copy(needed_raw_data)
for (v in mean_vars) {
  data_fivehour_filled[[v]] <- ifelse(is.na(needed_raw_data[[v]]), data_fivehour_rollmean[[v]], needed_raw_data[[v]])
}
```

# Load and process the AWN and AMF weather time series

Load all the auxiliary time series. Convert the date and time stamps to the same format as the SCAN time series. Select the appropriate columns and convert them to the same units as the SCAN time series (U.S. units) -- not strictly necessary but makes it easier to interpret. Use automated unit conversion for this. Note: solar radiation in SCAN is just in unit of W so it cannot be converted to W m<sup>-2</sup> without knowing the area.

Coarsen the time resolution of the AWN and AMF time series. AWN is in 15-minute time steps and AMF in 30-minute time steps. A rolling average with resolution 4 (right aligned so we line up an hour with the measurements preceding it in time) is used to coarsen from 15 minutes to 60 minutes, and resolution 2 for 30 minutes to 60 minutes. (For precipitation, sum is used instead of mean.) Remove all time points that are not an exact multiple of an hour.

As of 19 July, we now have time series with correct time stamps for both AMF RC1 and AMF RC2.

```{r}
awn_raw <- fread('project/weather_data/DHSVM_Pullman/Weather Data/AWN_15_300152.csv')
amf_rc1_raw <- fread('project/weather_data/DHSVM_Pullman/Weather Data/AMF_US-RC1_BASE_HH_2-5.csv', skip = 2)
amf_rc2_raw <- fread('project/weather_data/DHSVM_Pullman/Weather Data/AMF_US-RC2_BASE_HH_2-5.csv', skip = 2)

units_options(set_units_mode = 'standard')
convert_units <- function(x, old, new) as.numeric(set_units(set_units(x, old), new))

### Process AWN

# AWN missing values coded as 99999
awn_raw[awn_raw == 99999] <- NA

# Convert units for temperature (and average measurements 1 and 2)
awn_raw[, air_temp_C := convert_units(apply(cbind(AIR_TEMP_F, SECOND_AIR_TEMP_F), 1, mean, na.rm = TRUE), 'degreeF', 'degreeC')]

# Get only needed variables
awn_subset <- awn_raw[, .(TSTAMP_PST, air_temp_C, `RELATIVE_HUMIDITY_%`, PRECIP_INCHES, WIND_SPEED_MPH, SOLAR_RAD_WM2)]
awn_vars <- names(awn_subset)[-1]
awn_cont_vars <- awn_vars[!awn_vars %in% 'PRECIP_INCHES']

# Get rolling mean and sum
awn_rollmean <- copy(awn_subset)
awn_rollmean[, (awn_cont_vars) := lapply(.SD, frollmean, n = 4, align = 'right', fill = NA, algo = 'exact', hasNA = TRUE, na.rm = TRUE), .SDcols = awn_cont_vars]
awn_rollmean[, PRECIP_INCHES := frollsum(PRECIP_INCHES, n = 4, align = 'right', fill = NA, algo = 'exact', hasNA = TRUE, na.rm = TRUE)]

awn_rollmean[, Date := as.Date(TSTAMP_PST)]
awn_rollmean[, Time := hour(TSTAMP_PST)]
awn_rollmean[, Month := month(TSTAMP_PST)]
awn_rollmean[, Day := day(TSTAMP_PST)]
awn_rollmean[, Minute := minute(TSTAMP_PST)]

awn_rollmean <- awn_rollmean[Minute == 0, .(Date, Time, Month, Day, air_temp_C, `RELATIVE_HUMIDITY_%`, PRECIP_INCHES, WIND_SPEED_MPH, SOLAR_RAD_WM2)]

### PROCESS AMF
amf_rc1_raw[, station := 'RC1']
amf_rc2_raw[, station := 'RC2']

amf_raw <- rbindlist(list(amf_rc1_raw, amf_rc2_raw))

# Missing value code is -9999
amf_raw[amf_raw == -9999] <- NA

# Convert units (wind speed m/s to mph, precip mm to in)
amf_raw[, WS := convert_units(WS, 'm/s', 'mi/h')]
amf_raw[, P := convert_units(P, 'mm', 'in')]

# Convert timestamps to dates and times. Use END date. RC2 seems to have some issues.
amf_raw[, Date := as.Date(substr(as.character(TIMESTAMP_END), 1, 8), format = '%Y%m%d')]
amf_raw[, Time := as.numeric(substr(as.character(TIMESTAMP_END), 9, 10))]
amf_raw[, Minute := as.numeric(substr(as.character(TIMESTAMP_END), 11, 12))]
amf_raw[, Month := month(Date)]
amf_raw[, Day := day(Date)]

# Get only needed variables. PPFD is used for solar radiation because it does not look like SW is in there. 
amf_subset <- amf_raw[, .(station, Date, Time, Month, Day, Minute, TA, WS, RH, PPFD_IN, P)]

amf_vars <- c('TA', 'WS', 'RH', 'PPFD_IN', 'P')
amf_cont_vars <- c('TA', 'WS', 'RH', 'PPFD_IN')

# Get rolling mean and sum. Do separately for RC1 and RC2
amf_rc1_rollmean <- amf_subset[station == 'RC1']
amf_rc1_rollmean[, (amf_cont_vars) := lapply(.SD, frollmean, n = 2, align = 'right', fill = NA, algo = 'exact', hasNA = TRUE, na.rm = TRUE), .SDcols = amf_cont_vars]
amf_rc1_rollmean[, P := frollsum(P, n = 2, align = 'right', fill = NA, algo = 'exact', hasNA = TRUE, na.rm = FALSE)]

amf_rc1_rollmean <- amf_rc1_rollmean[Minute == 0, .(Date, Time, Month, Day, TA, WS, RH, PPFD_IN, P)]

amf_rc2_rollmean <- amf_subset[station == 'RC2']
amf_rc2_rollmean[, (amf_cont_vars) := lapply(.SD, frollmean, n = 2, align = 'right', fill = NA, algo = 'exact', hasNA = TRUE, na.rm = TRUE), .SDcols = amf_cont_vars]
amf_rc2_rollmean[, P := frollsum(P, n = 2, align = 'right', fill = NA, algo = 'exact', hasNA = TRUE, na.rm = FALSE)]

amf_rc2_rollmean <- amf_rc2_rollmean[Minute == 0, .(Date, Time, Month, Day, TA, WS, RH, PPFD_IN, P)]
```

Set the names in all the time series to be the same, as well as the order of the columns, for easier processing later. Write them to a file.

```{r}
setnames(data_fivehour_filled, c('Date', 'Time', 'T_degC', 'WS_mph', 'RH_pct', 'SR_in_Wm2', 'PRCP_in', 'Month', 'Day'))
scan_ts <- data_fivehour_filled[, .(Date, Month, Day, Time, T_degC, WS_mph, RH_pct, SR_in_Wm2, PRCP_in)]

setnames(awn_rollmean, c('Date', 'Time', 'Month', 'Day', 'T_degC', 'RH_pct', 'PRCP_in', 'WS_mph', 'SR_in_Wm2'))
awn_ts <- awn_rollmean[, .(Date, Month, Day, Time, T_degC, WS_mph, RH_pct, SR_in_Wm2, PRCP_in)]

setnames(amf_rc1_rollmean, c('Date', 'Time', 'Month', 'Day', 'T_degC', 'WS_mph', 'RH_pct', 'PPFD', 'PRCP_in'))
amfrc1_ts <- amf_rc1_rollmean[, .(Date, Month, Day, Time, T_degC, WS_mph, RH_pct, PPFD, PRCP_in)]

setnames(amf_rc2_rollmean, c('Date', 'Time', 'Month', 'Day', 'T_degC', 'WS_mph', 'RH_pct', 'PPFD', 'PRCP_in'))
amfrc2_ts <- amf_rc2_rollmean[, .(Date, Month, Day, Time, T_degC, WS_mph, RH_pct, PPFD, PRCP_in)]
```

```{r, eval = FALSE}
save(scan_ts, awn_ts, amfrc1_ts, amfrc2_ts, file = 'project/weather_data/4ts_intermediate.RData')
```


# Side-by-side comparison of time series

Just for ease of plotting, take the daily min and max temp, the daily mean windspeed, the daily mean RH%, mean radiation, and total precipitation.

```{r}
daily_summ <- function(ts) {
  ts <- copy(ts)
  if ("PPFD" %in% names(ts)) setnames(ts, 'PPFD', 'SR_in_Wm2')
  ts[, .(T_min = min(T_degC), T_max = max(T_degC), WS = mean(WS_mph), RH = mean(RH_pct), SR = mean(SR_in_Wm2), P = sum(PRCP_in)), by = .(Date, Month, Day)]
}

SCAN_daily <- daily_summ(scan_ts)
AWN_daily <- daily_summ(awn_ts)
AMFRC1_daily <- daily_summ(amfrc1_ts)
AMFRC2_daily <- daily_summ(amfrc2_ts)

# Make all longform and join
date_vars <- c('Date', 'Month', 'Day')
SCAN_daily_long <- melt(SCAN_daily, id.vars = date_vars)
AWN_daily_long <- melt(AWN_daily, id.vars = date_vars)
AMFRC1_daily_long <- melt(AMFRC1_daily, id.vars = date_vars)
AMFRC2_daily_long <- melt(AMFRC2_daily, id.vars = date_vars)
SCAN_daily_long[, time_series := 'SCAN']
AWN_daily_long[, time_series := 'AWN']
AMFRC1_daily_long[, time_series := 'AMF RC1']
AMFRC2_daily_long[, time_series := 'AMF RC2']

all_daily <- rbindlist(list(SCAN_daily_long, AWN_daily_long, AMFRC1_daily_long, AMFRC2_daily_long))
```

```{r}
ggplot(all_daily, aes(x = Date, y = value, color = time_series)) +
  geom_point(size = 0.25) +
  facet_wrap(~ variable, scales = 'free_y')
```

Also make pairwise scatter plots for SCAN vs AMF and SCAN vs AWN. The y=x line is shown. It looks like the temperature of SCAN closely tracks AWN except that SCAN has slightly more "extreme" temperature where it tends to have lower minimum and higher maximum, but really only slightly, it has quite a bit higher average wind speed, RH and SR very similar, and P also pretty similar but maybe SCAN skews a tiny bit wetter. The exact slope of the relationship really doesn't matter as long as it is a reliable correlation which it certainly appears to be.

```{r}
all_daily_byTS <- dcast(all_daily, Date+Month+Day+variable ~ time_series)

ggplot(all_daily_byTS, aes(x = SCAN, y = AWN)) +
  geom_point(alpha = 0.25) +
  geom_abline(slope = 1, intercept = 0, color = 'red') +
  facet_wrap(~ variable, scales = 'free')
```

The Ameriflux RC1 is not as close as AWN but still pretty good. It looks like AMF has a warmer minimum temperature than SCAN, less wind, less humid, but maybe more precipitation. SR is probably the same but they are not in the same units thus why the red line does not line up. AMF RC2 is very similar to AMF RC1 but somewhat drier and windier.

```{r}
ggplot(all_daily_byTS, aes(x = SCAN, y = `AMF RC1`)) +
  geom_point(alpha = 0.25) +
  geom_abline(slope = 1, intercept = 0, color = 'red') +
  facet_wrap(~ variable, scales = 'free')
```

```{r}
ggplot(all_daily_byTS, aes(x = SCAN, y = `AMF RC2`)) +
  geom_point(alpha = 0.25) +
  geom_abline(slope = 1, intercept = 0, color = 'red') +
  facet_wrap(~ variable, scales = 'free')
```

# Predictive model

Now let's make predictive models for each weather variable to fill gaps in the time series. We will use a cross-validation approach to find the statistical model with the best predictive power for the overlapping sections, and then apply that to fill the gaps. 

Start by joining the raw (non-summarized) data by date and time for each of the four time series. 

```{r}
id_vars <- c('Date','Month','Day','Time')
scan_long <- melt(scan_ts, id.vars = id_vars, value.name = 'SCAN')
awn_long <- melt(awn_ts, id.vars = id_vars, value.name = 'AWN')
amfrc1_long <- melt(amfrc1_ts, id.vars = id_vars, value.name = 'AMFRC1')
amfrc2_long <- melt(amfrc2_ts, id.vars = id_vars, value.name = 'AMFRC2')

all_long <- Reduce(\(...) merge(..., all = TRUE), list(scan_long, awn_long, amfrc1_long, amfrc2_long))

# Correct the PPFD and SR names
all_long[variable %in% c('PPFD', 'SR_in_Wm2'), variable := 'SR_in_Wm2']
```

Now that we have the data ready, we can fit a very basic model. I think for imputation purposes it is fine to ignore covariation between the different weather variables, as well as temporal autocorrelation, as long as we can get adequate predictive power. Let's just use AWN for imputation and see how well it does on the data we have. If it is not good enough, we can bring in the AMF datasets, or try more sophisticated methods.

Apply relevant transformations to some of the variables. Use 10-fold cross-validation to train the model.

## Temperature

First let's try temperature. Compare how well each of the three time series do when used as predictors of SCAN in the 10-fold cross-validated linear model.

```{r}
temp_awn_fit <- train(
  form = SCAN ~ AWN,
  data = all_long[variable == 'T_degC' & !is.na(SCAN) & !is.na(AWN)],
  method = 'lm',
  trControl = trainControl(method = 'cv', number = 10)
)

temp_amf1_fit <- train(
  form = SCAN ~ AMFRC1,
  data = all_long[variable == 'T_degC' & !is.na(SCAN) & !is.na(AMFRC1)],
  method = 'lm',
  trControl = trainControl(method = 'cv', number = 10)
)

temp_amf2_fit <- train(
  form = SCAN ~ AMFRC2,
  data = all_long[variable == 'T_degC' & !is.na(SCAN) & !is.na(AMFRC2)],
  method = 'lm',
  trControl = trainControl(method = 'cv', number = 10)
)
```

```{r, echo = FALSE}
temp_results <- data.frame(predictor = c('AWN', 'AMF RC1', 'AMF RC2'), 
                           Rsquared = c(temp_awn_fit$results$Rsquared, temp_amf1_fit$results$Rsquared, temp_amf2_fit$results$Rsquared),
                           RMSE = c(temp_awn_fit$results$RMSE, temp_amf1_fit$results$RMSE, temp_amf2_fit$results$RMSE))

gt(temp_results) %>%
  fmt_number(columns = c(Rsquared, RMSE), n_sigfig = 3)
```

The cross-validated AWN prediction has a higher R-squared and is "wrong" by an average of 1.5 degrees C versus >2.5 for the Ameriflux predictions. So, we will just go with the AWN prediction. I am just going to use AWN for all the other variables and not even try the Ameriflux.

## Wind speed

Because wind speed is non-negative, we cannot just do a linear model assuming a normally distributed response variable because the predictions could then be negative. We also cannot just do a log transformation because of the zero values. First, let's just try to do a `log(x+0.1)` transformation and then see what we get. Also round the result in post-processing.

```{r}
ws_dat <- all_long[variable == 'WS_mph' & !is.na(SCAN) & !is.na(AWN)]
ws_dat[, SCAN_tr := log(SCAN + 0.01)]
ws_dat[, AWN_tr := log(AWN + 0.01)]

ws_awn_fit <- train(
  form = SCAN_tr ~ AWN_tr,
  data = ws_dat,
  method = 'lm',
  trControl = trainControl(method = 'cv', number = 10)
)
```


## Relative humidity

This one is annoying because relative humidity is between 0 and 1. We have some values of exactly 1 (100% RH) but no values of exactly 0. There are about 1000 values with 100% RH in the SCAN time series. We will just get around it by subtracting 0.1 from the RH values and doing a logit transformation, predicting, then back-transforming.

```{r}
rh_dat <- all_long[variable == 'RH_pct' & !is.na(SCAN) & !is.na(AWN)]
rh_dat[, SCAN_tr := qlogis(SCAN/100 - 0.001)]
rh_dat[, AWN_tr := qlogis(AWN/100 - 0.001)]

rh_awn_fit <- train(
  form = SCAN_tr ~ AWN_tr,
  data = rh_dat,
  method = 'lm',
  trControl = trainControl(method = 'cv', number = 10)
)
```


## Solar radiation

```{r}
sr_dat <- all_long[variable == 'SR_in_Wm2' & !is.na(SCAN) & !is.na(AWN)]
sr_dat[, SCAN_tr := log(SCAN + 0.01)]
sr_dat[, AWN_tr := log(AWN + 0.01)]

sr_awn_fit <- train(
  form = SCAN_tr ~ AWN_tr,
  data = sr_dat,
  method = 'lm',
  trControl = trainControl(method = 'cv', number = 10)
)
```